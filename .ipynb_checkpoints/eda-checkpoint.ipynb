{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: COMPAS Recidivism Data\n",
    "\n",
    "This notebook analyzes the COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) algorithm data, focusing on potential racial bias in recidivism predictions.\n",
    "\n",
    "## Context\n",
    "\n",
    "COMPAS is used by judges and parole officers to score criminal defendants' likelihood of reoffending. ProPublica's analysis revealed potential racial bias in the algorithm's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette('deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Datasets\n",
    "\n",
    "We have multiple datasets available:\n",
    "1. compas-scores-raw.csv - Raw COMPAS scores\n",
    "2. cox-violent-parsed.csv - Parsed violent recidivism data\n",
    "3. cox-violent-parsed_filt.csv - Filtered violent recidivism data\n",
    "4. propublica_data_for_fairml.csv - Simplified dataset for fairness analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the datasets\n",
    "compas_raw = pd.read_csv('dataset/compas-scores-raw.csv')\n",
    "violent_parsed = pd.read_csv('dataset/cox-violent-parsed.csv')\n",
    "violent_filtered = pd.read_csv('dataset/cox-violent-parsed_filt.csv')\n",
    "fairml_data = pd.read_csv('dataset/propublicaCompassRecividism_data_fairml.csv/propublica_data_for_fairml.csv')\n",
    "\n",
    "print(\"\\nCompas Raw Shape:\", compas_raw.shape)\n",
    "print(\"Violent Parsed Shape:\", violent_parsed.shape)\n",
    "print(\"Violent Filtered Shape:\", violent_filtered.shape)\n",
    "print(\"FairML Data Shape:\", fairml_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Let's look at the structure of each dataset\n",
    "print(\"\\nCompas Raw Columns:\")\n",
    "print(compas_raw.columns.tolist())\n",
    "\n",
    "print(\"\\nViolent Parsed Columns:\")\n",
    "print(violent_parsed.columns.tolist())\n",
    "\n",
    "print(\"\\nViolent Filtered Columns:\")\n",
    "print(violent_filtered.columns.tolist())\n",
    "\n",
    "print(\"\\nFairML Data Columns:\")\n",
    "print(fairml_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Basic statistics for the raw COMPAS scores\n",
    "print(\"\\nCompas Raw Summary Statistics:\")\n",
    "compas_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Racial Bias Analysis\n",
    "\n",
    "Let's analyze the racial disparities in COMPAS predictions vs actual recidivism rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to calculate recidivism prediction accuracy by race\n",
    "def analyze_racial_bias(df, race_col, score_col, recid_col):\n",
    "    results = []\n",
    "    for race in df[race_col].unique():\n",
    "        race_df = df[df[race_col] == race]\n",
    "        \n",
    "        # True negatives (correctly predicted no recidivism)\n",
    "        tn = len(race_df[(race_df[score_col].isin(['Low'])) & (race_df[recid_col] == 0)])\n",
    "        \n",
    "        # False positives (incorrectly predicted recidivism)\n",
    "        fp = len(race_df[(race_df[score_col].isin(['Medium', 'High'])) & (race_df[recid_col] == 0)])\n",
    "        \n",
    "        # True positives (correctly predicted recidivism)\n",
    "        tp = len(race_df[(race_df[score_col].isin(['Medium', 'High'])) & (race_df[recid_col] == 1)])\n",
    "        \n",
    "        # False negatives (incorrectly predicted no recidivism)\n",
    "        fn = len(race_df[(race_df[score_col].isin(['Low'])) & (race_df[recid_col] == 1)])\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total = tn + fp + tp + fn\n",
    "        false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "        accuracy = (tp + tn) / total if total > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'Race': race,\n",
    "            'Total': total,\n",
    "            'False Positive Rate': false_positive_rate,\n",
    "            'False Negative Rate': false_negative_rate,\n",
    "            'Accuracy': accuracy\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze racial bias in the raw COMPAS data\n",
    "compas_raw['score_text'] = pd.cut(compas_raw['decile_score'], \n",
    "                                 bins=[-np.inf, 4, 7, np.inf], \n",
    "                                 labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "racial_bias_analysis = analyze_racial_bias(compas_raw, \n",
    "                                          'race', \n",
    "                                          'score_text',\n",
    "                                          'is_recid')\n",
    "\n",
    "print(\"Racial Bias Analysis:\")\n",
    "display(racial_bias_analysis)\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(racial_bias_analysis))\n",
    "\n",
    "plt.bar(index, racial_bias_analysis['False Positive Rate'], bar_width, label='False Positive Rate')\n",
    "plt.bar(index + bar_width, racial_bias_analysis['False Negative Rate'], bar_width, label='False Negative Rate')\n",
    "plt.bar(index + 2*bar_width, racial_bias_analysis['Accuracy'], bar_width, label='Accuracy')\n",
    "\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Rate')\n",
    "plt.title('COMPAS Prediction Metrics by Race')\n",
    "plt.xticks(index + bar_width, racial_bias_analysis['Race'], rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Violent Recidivism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze violent recidivism predictions\n",
    "violent_analysis = analyze_racial_bias(violent_parsed,\n",
    "                                      'race',\n",
    "                                      'v_score_text',\n",
    "                                      'is_violent_recid')\n",
    "\n",
    "print(\"Violent Recidivism Analysis:\")\n",
    "display(violent_analysis)\n",
    "\n",
    "# Visualize violent recidivism analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "index = np.arange(len(violent_analysis))\n",
    "\n",
    "plt.bar(index, violent_analysis['False Positive Rate'], bar_width, label='False Positive Rate')\n",
    "plt.bar(index + bar_width, violent_analysis['False Negative Rate'], bar_width, label='False Negative Rate')\n",
    "plt.bar(index + 2*bar_width, violent_analysis['Accuracy'], bar_width, label='Accuracy')\n",
    "\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Rate')\n",
    "plt.title('Violent Recidivism Prediction Metrics by Race')\n",
    "plt.xticks(index + bar_width, violent_analysis['Race'], rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Using the FairML dataset for feature importance analysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Prepare the data\n",
    "feature_cols = [col for col in fairml_data.columns if col != 'two_year_recid']\n",
    "X = fairml_data[feature_cols].copy()\n",
    "y = fairml_data['two_year_recid']\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Train a random forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('Feature Importance in Predicting Recidivism')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
